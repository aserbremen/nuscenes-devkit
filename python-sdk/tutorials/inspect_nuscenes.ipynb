{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 panoptic,\n",
      "Done loading in 21.835 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 5.8 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os.path as osp\n",
    "import cv2\n",
    "# from nuscenes import NuScenes\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.geometry_utils import BoxVisibility\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/data/datasets/nuscenes', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from nuscenes.utils.geometry_utils import view_points\n",
    "from nuscenes.utils.data_classes import Box\n",
    "\n",
    "def cv2_put_multi_line_text(im: np.ndarray,\n",
    "                            text: str,\n",
    "                            center: Tuple,\n",
    "                            color: Tuple,\n",
    "                            font=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                            font_scale=0.5,\n",
    "                            thickness=1) -> None:\n",
    "    text_size, _ = cv2.getTextSize(\"dummy_text\", font, font_scale, thickness)\n",
    "    line_height = text_size[1] + 5\n",
    "    y0 = int(center[1])\n",
    "    for i, text_line in enumerate(text.split('\\n')):\n",
    "        y = y0 + i * line_height\n",
    "        cv2.putText(im, text_line, (int(center[0]), y),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, font_scale, color[::-1], thickness, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "font_scale = 0.5\n",
    "thickness = 1\n",
    "\n",
    "def box_render_cv2_text(box: Box,\n",
    "                    nusc: NuScenes,\n",
    "                    im: np.ndarray,\n",
    "                    view: np.ndarray = np.eye(3),\n",
    "                    normalize: bool = False,\n",
    "                    colors: Tuple = ((0, 0, 255), (255, 0, 0), (155, 155, 155)),\n",
    "                    linewidth: int = 2,\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Renders box using OpenCV2.\n",
    "    :param Box: Box to be rendered\n",
    "    :param nusc: Active NuScenes object\n",
    "    :param im: <np.array: width, height, 3>. Image array. Channels are in BGR order.\n",
    "    :param view: <np.array: 3, 3>. Define a projection if needed (e.g. for drawing projection in an image).\n",
    "    :param is_key_frame\n",
    "    :param normalize: Whether to normalize the remaining coordinate.\n",
    "    :param colors: ((R, G, B), (R, G, B), (R, G, B)). Colors for front, side & rear.\n",
    "    :param linewidth: Linewidth for plot.\n",
    "    \"\"\"\n",
    "    corners = view_points(box.corners(), view, normalize=normalize)[:2, :]\n",
    "\n",
    "    def draw_rect(selected_corners, color):\n",
    "        prev = selected_corners[-1]\n",
    "        for corner in selected_corners:\n",
    "            cv2.line(im,\n",
    "                     (int(prev[0]), int(prev[1])),\n",
    "                     (int(corner[0]), int(corner[1])),\n",
    "                     color, linewidth)\n",
    "            prev = corner\n",
    "\n",
    "    # Draw the sides\n",
    "    for i in range(4):\n",
    "        cv2.line(im,\n",
    "                 (int(corners.T[i][0]), int(corners.T[i][1])),\n",
    "                 (int(corners.T[i + 4][0]), int(corners.T[i + 4][1])),\n",
    "                 colors[2][::-1], linewidth)\n",
    "\n",
    "    # Draw front (first 4 corners) and rear (last 4 corners) rectangles(3d)/lines(2d)\n",
    "    draw_rect(corners.T[:4], colors[0][::-1])\n",
    "    draw_rect(corners.T[4:], colors[1][::-1])\n",
    "\n",
    "    # Draw line indicating the front\n",
    "    center_bottom_forward = np.mean(corners.T[2:4], axis=0)\n",
    "    center_bottom = np.mean(corners.T[[2, 3, 7, 6]], axis=0)\n",
    "    cv2.line(im,\n",
    "             (int(center_bottom[0]), int(center_bottom[1])),\n",
    "             (int(center_bottom_forward[0]), int(center_bottom_forward[1])),\n",
    "             colors[0][::-1], linewidth)\n",
    "\n",
    "    # Add some text to the bounding box\n",
    "    # Create text to be written\n",
    "    attribute_tokens =  nusc.get('sample_annotation', box.token)['attribute_tokens']\n",
    "    text = box.name\n",
    "    for attribute_token in attribute_tokens:\n",
    "        attribute = nusc.get('attribute', attribute_token)\n",
    "        text += '\\n' + attribute['name']\n",
    "    visibility = nusc.get('sample_annotation', box.token)['visibility_token']\n",
    "    text += '\\nvisibility ' + visibility\n",
    "    # Setup multi line text\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    font_scale = 0.5\n",
    "    thickness = 1\n",
    "    text_size, _ = cv2.getTextSize(box.name, font, font_scale, thickness)\n",
    "    line_height = text_size[1] + 5\n",
    "    center = np.mean(corners.T[:], axis=0)\n",
    "    y0 = int(center[1])\n",
    "    for i, text_line in enumerate(text.split('\\n')):\n",
    "        y = y0 + i * line_height\n",
    "        cv2.putText(im, text_line, (int(center[0]), y),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, font_scale, colors[0][::-1], thickness, cv2.LINE_AA)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_birth_and_prebirth(prev_im: np.ndarray,\n",
    "                              current_im: np.ndarray,\n",
    "                              resize_factor: float) -> np.ndarray:\n",
    "    \n",
    "    prev_im_shrink = cv2.resize(prev_im, None, fx=resize_factor, fy=resize_factor, interpolation=cv2.INTER_AREA)\n",
    "    current_im_shrink = cv2.resize(current_im, None, fx=resize_factor, fy=resize_factor, interpolation=cv2.INTER_AREA)\n",
    "    return np.vstack([prev_im_shrink, current_im_shrink])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel = 'CAM_FRONT'\n",
    "\n",
    "for idx, scene in enumerate(nusc.scene):\n",
    "    first_sample_rec = nusc.get('sample', scene['first_sample_token'])\n",
    "    first_sd_rec = nusc.get('sample_data', first_sample_rec['data'][channel])\n",
    "    current_sd_rec = first_sd_rec\n",
    "    prev_sd_rec = None\n",
    "    prev_im = None\n",
    "\n",
    "    window_name= '{}'.format(scene['name'])\n",
    "    # cv2.namedWindow(window_name)\n",
    "    # cv2.moveWindow(window_name, 0, 0)\n",
    "    \n",
    "    has_more_frames = True\n",
    "    break_all = False\n",
    "    break_scene = False\n",
    "    milliseconds = 0\n",
    "    unique_instances = []\n",
    "    minimum_visibility = 2\n",
    "    while has_more_frames:\n",
    "\n",
    "        # Get annotations, boxes, camera_intrinsic\n",
    "        # When using BoxVisibility.ALL objects are detected too late in certain cases\n",
    "        impath, boxes, camera_intrinsic = nusc.get_sample_data(current_sd_rec['token'], box_vis_level=BoxVisibility.ANY)\n",
    "        if not osp.exists(impath):\n",
    "            raise Exception('Error: Missing image %s' % impath)\n",
    "\n",
    "        current_im = cv2.imread(impath)\n",
    "        # if current_sd_rec['is_key_frame']:\n",
    "        #     cv2_put_multi_line_text(current_im, \"KEYFRAME\", (int(current_im.shape[1]/2), int(current_im.shape[0]/2-80)), (255, 0, 0))\n",
    "        im_contains_unique_instance = False\n",
    "        is_first_frame = False\n",
    "        # if prev_im is None:\n",
    "        #     prev_im = current_im.copy()\n",
    "        #     is_first_frame = True\n",
    "            # cv2_put_multi_line_text(prev_im, \"First frame\", (int(prev_im.shape[1]/2), int(prev_im.shape[0]/2-25)), (0, 0, 0))\n",
    "            # cv2_put_multi_line_text(current_im, \"First frame\", (int(prev_im.shape[1]/2), int(prev_im.shape[0]/2-25)), (0, 0, 0))\n",
    "\n",
    "        if current_sd_rec['is_key_frame']:    \n",
    "            skip_box = False\n",
    "            for box in boxes:\n",
    "                sample_annotation = nusc.get('sample_annotation', box.token)\n",
    "                instance = nusc.get('instance', sample_annotation['instance_token'])\n",
    "                category = nusc.get('category', instance['category_token'])\n",
    "                # Exclude certain objects\n",
    "                if category['index'] > 8 and category['index'] < 14:\n",
    "                    continue\n",
    "                for attribute_token in sample_annotation['attribute_tokens']:\n",
    "                    attribute_name = nusc.get('attribute', attribute_token)['name']\n",
    "                    if 'without_rider' in attribute_name or 'sitting' in attribute_name:\n",
    "                        skip_box = True\n",
    "                if skip_box:\n",
    "                    continue\n",
    "\n",
    "                if int(sample_annotation['visibility_token']) < minimum_visibility:\n",
    "                    continue\n",
    "\n",
    "                # Gather unique instances\n",
    "                instance_token = sample_annotation['instance_token']\n",
    "\n",
    "                # print(current_sd_rec)\n",
    "                if instance_token not in unique_instances:\n",
    "                    im_contains_unique_instance = True\n",
    "                    unique_instances.append(instance_token)\n",
    "                    # Check if this is the first frame of the scene, which means that the object could not have been born\n",
    "                    if current_sd_rec['timestamp'] == first_sd_rec['timestamp']: \n",
    "                        pass\n",
    "                    else:\n",
    "                        # This box can mean a potential object birth\n",
    "                        c = nusc.explorer.get_color(box.name)\n",
    "                        box_render_cv2_text(box, nusc, current_im, view=camera_intrinsic, normalize=True, colors=(c, c, c))\n",
    "\n",
    "                        # font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                        # font_scale = 0.8\n",
    "                        # thickness = 1\n",
    "                        # text_line = \"visibility \" + str(sample_annotation['visibility_token'])\n",
    "                        # cv2.putText(current_im, text_line, (int(current_im.shape[1]/2), int((current_im.shape[0]/2))),\n",
    "                        #             cv2.FONT_HERSHEY_COMPLEX, font_scale, c[::-1], thickness, cv2.LINE_AA)\n",
    "            \n",
    "        # birth_im = render_birth_and_prebirth(prev_im, current_im, 0.7)\n",
    "        \n",
    "        cv2.imshow(\"birth image\", current_im)\n",
    "        if im_contains_unique_instance or is_first_frame:\n",
    "            key = cv2.waitKey(0)\n",
    "        else:\n",
    "            key = cv2.waitKey(1)\n",
    "        if key == 27:  # if ESC is pressed, exit.\n",
    "            cv2.destroyAllWindows()\n",
    "            break_all = True\n",
    "            break_scene = True\n",
    "            break\n",
    "\n",
    "                    # for attribute_token in sample_annotation['attribute_tokens']:\n",
    "                    #     attribute = nusc.get('attribute', attribute_token)\n",
    "                        # print(\"attribute\", attribute)\n",
    "\n",
    "        # cv2.imshow(window_name, current_im)\n",
    "        # key = cv2.waitKey(milliseconds)\n",
    "        # if key == 32: # if space is pressed, pause.\n",
    "        #     key = cv2.waitKey()\n",
    "        # if key == 27: # if ESC is pressed, exit.\n",
    "        #     break_all = True\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     break\n",
    "        # if key == 110: # if n is pressed, skip current scene.\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     break\n",
    "\n",
    "        if break_scene:\n",
    "            break\n",
    "\n",
    "        if current_sd_rec['next'] == '':\n",
    "            has_more_frames = False\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            prev_im = current_im    \n",
    "            prev_sd_rec = current_sd_rec\n",
    "            current_sd_rec = nusc.get('sample_data', current_sd_rec['next'])\n",
    "        \n",
    "    if break_all:\n",
    "        break\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "318541fadf8f6473a5ac117b97e36e34b5dead6f3ba376595b86165903d1f35a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nuscenes_local': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
